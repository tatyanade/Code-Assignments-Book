[
    {
        "in": 1,
        "titles": "Iterative Pattern (Wallpaper)",
        "shortdescription": "Generating a texture or textile design\n",
        "level": "All levels ",
        "tagsstem": "iteration, functional abstraction, coordinates, graphics primitives, graphics transforms, tesselation, symmetries",
        "tagsarts": "pattern, texture, rhythm, shape, curves",
        "learningobjectives": "•  Develop an understanding of drawing functions and the Cartesian coordinate system\n•  Use functional abstraction to encapsulate the code for a modular design element\n•  Gain experience generating high-resolution raster and/or vector designs",
        "brief": "Write code to generate a tiling pattern or textural composition, such as for wallpaper or fabric. Give consideration to aesthetic issues like symmetry, rhythm, color; detail at multiple scales; precise control of shape; and the balance between organic and geometric forms. Your pattern should be designed so that it could be infinitely tiled or extended. Design something you would actually like to put on the walls of your home, or which you could imagine yourself actually wearing. Export your pattern in a high-resolution format, and print it as large as possible. Projects will be critiqued at the pin-board. Remember to sketch first.",
        "variations": "•  Experiment with 2D graphics transformations, such as rotate(), scale(), and mirror reflections.\n•  Use *nested iteration* to develop 2D rhythms or other gridlike visual structures.\n•  Create a *helper function* to encapsulate the way in which a complex visual element (such as a flower, animal, fruit, fleur-de-lys, etc.) is rendered throughout your design.\n•  Strictly using code, reproduce a pre-existing textile or wallpaper design.\n•  Make a kaleidoscope, by incorporating a photographic image or video feed into the pattern.\n•  Have your pattern printed on a real textile, wrapping paper, etc. by an online fabrication service such as Spoonflower, Constrvct, or Print All Over Me. Consider other output devices for realizing your pattern, such as computer-controlled laser cutters, knitting machines, and lace-making services.",
        "advancedstudents": "Think beyond the rectangular grid. Investigate \"wallpaper group\" symmetries; convex uniform tilings; aperiodic tiles; texture synthesis and re-synthesis. Experiment with the use of particle systems for placing elements.",
        "makingitmeaningful": "Pattern is the starting point from which we perceive and impose order in the world. The art of visual pattern-making is as old as humankind itself, and countless examples abound, whether functional, decorative or expressive, in forms like mosaics, calendars, tapestry, quilting, jewelry, calligraphy, furniture, architecture, and more. There is an intimate connection between pattern design, visual rhythm, geometry, mathematics, and iterative algorithms; this prompt invites students to hone their understanding of these relationships in purely formal terms. Realizing a design *physically*, especially through digital printing or fabrication in an unusual material or size, can be a watershed moment of synthesis for students who crave \"something real\". ",
        "titlegray": 255,
        "fullpageimage": "wallpaper/todo_spamghetto_2_fullpage.jpg",
        "layout": 11,
        "image": "wallpaper/polya_tallhalf.png\nwallpaper/marrakech_tiles_onethird.jpg\nwallpaper/reas_pill_a_day_onethird.jpg\nwallpaper/gondek_gallifreyan_onethird.png",
        "aspirationcaptions": "1. In *Spamgetto* (2009), the Italian design agency Todo presents wallpaper whose design is computationally generated from thousands of spam emails. https://www.flickr.com/photos/todotoit/sets/72157616412434905/\n\n2. George Pólya's illustrations (1924) of the seventeen periodic plane symmetry groups had a profound influence on the algorithmic patternmaking of M.C. Escher.\n\n3. Zellige terracotta tiles in Marrakech (17th century) form edge-to-edge, regular and other tessellations. Photo by Ian Alexander, 2000. From Wikipedia. https://en.wikipedia.org/wiki/Tessellation.\n\n4. Casey Reas's *One Non-Narcotic Pill A Day* (2013) presents a dynamic collage pattern generated from a video recording.\n\n5. Alison Gondek, an introductory programming student at CMU, used JavaScript to create this pattern inspired by the “Circular Gallifreyan” language from *Doctor Who*.",
        "additionalreferences": "\"Aperiodic Tiling\". In Wikipedia. https://en.wikipedia.org/wiki/Aperiodic_tiling\nBailey, David. *David Bailey's World of Escher-like Tessellations*. http://www.tess-elation.co.uk/\nGrünbaum, B., & Shephard, G. C. (1987). *Tilings and patterns*. Freeman.\nJones, O. (1868). *The grammar of ornament*. B. Quaritch.\nSchattschneider, D. \"The Mathematical Side of M. C. Escher,\" in *AMS Notices* 57: 706-718, 2010. http://www.ams.org/journals/notices/201006/rtx100600706p.pdf\n\"Texture Synthesis\". In Wikipedia. https://en.wikipedia.org/wiki/Texture_synthesis\n\"Wallpaper Collection\", Historic New England. http://www.historicnewengland.org/collections-archives-exhibitions/collections-access/highlights/wallpaper\n\"Wallpaper Groups\". In Wikipedia. https://en.wikipedia.org/wiki/Wallpaper_group\n\nAlso see works by: Casey Reas, Marius Watz, Lia, Jonathan McCabe, Mitchell Whitelaw, Tina Frank, Joshua Davis, Dave Bollinger, Holger Lippmann."
    },
    {
        "in": 1,
        "titles": "Face Generator",
        "shortdescription": "Drawing parametric faces",
        "level": "All levels",
        "tagsstem": "parametric design, constrained randomness, graphics primitives, variables",
        "tagsarts": "portraiture, physiognomy, character design, puppets, avatars",
        "learningobjectives": "•  Develop familiarity with drawing functions and parametric form\n•  Apply generative principles to expressive character design\n•  Develop skills as a meta-designer",
        "brief": "Write code to create a face design which is parameterized by at least three dimensions of variability, but preferably more. For example, you might have variables that specify the size, position, color, or other visual characteristics of the eyes, nose, and mouth. The variations in these features may be used to alter the face’s expression (happy, sad, angry, etc.); the face’s identity (John, Mary, etc.); and/or the face’s species (cat, monkey, zombie, alien, etc.). Give consideration to *continuous* parameters (such as nose size or eyebrow position), versus *discrete* parameters (such as the presence of piercings, or the number of eyeballs). Your system should generate a new face whenever the user clicks the mouse.",
        "variations": "•  Consider whether your faces are 2D or 3D, and whether they are generated in frontal, profile, and/or three-quarters view.\n•  Give special consideration to controlling the precise *shape* of face parts, such as the curves of the nose, chin, ears, and jowls.\n•  Consider characteristics like skin color, stubble, hairstyle, blemishes, interpupillary distance, facial assymmetry, cephalic index, prognathism, etc.\n•  Use your software to generate a deck of collectible trading cards (like Pokémon or baseball cards), featuring a group of imaginary monsters. Print out the cards.\n•  For visualization students, try using actual multivariate data as the basis for generating new faces, rather than randomness.\n•  Add functionality to your face so that it responds to audio or microphone input. \n•  This project can be used as a follow-up to a preliminary exercise: using code to render a static self-portrait.",
        "advancedstudents": "Create a parameterized facial puppet which is controlled by signals from a real-time face tracker (such as *FaceOSC*). Practice a brief monologue and record a screen-captured video performance with your avatar.",
        "makingitmeaningful": "Humans are equipped with an exquisite sensitivity to faces. From infancy we easily recognize faces, and can detect very subtle shifts in facial expressions, often being able to discern the slightest change in mood and sincerity in ways that remain impossible for computers. From faces we are also readily able to identify family resemblances, or \"strangers\" in crowds, and we are transfixed by the ways in which the lines on a face can reveal a person's life history. Kyle McDonald writes that \"faces are so important that the impairment of our face-processing ability is seen as a disorder, called *prosopagnosia*, while unconsciously seeing faces where there are none is an almost universal kind of *pareidolia*.\"\n\nThis assignment draws inspiration from the “Chernoff Face\" data visualization technique, which leverages this sensitivity by using facial features to represent multivariate data. In Chernoff Faces, features such as eyes, ears, mouth and nose represent data according to their shape, size, placement and orientation. Whereas Chernoff (1973) used 18 variables to *synthesize* a face, Paul Ekman’s \"Facial Action Coding System\" uses 46 dimensions to *analyze* a facial expression, each corresponding to the action of a different facial muscle.",
        "titlegray": 0,
        "fullpageimage": "generative_face/moka_faces_1_fullpage.jpg",
        "layout": 20,
        "image": "generative_face/hdh_stranger_visions_quarter.jpg\ngenerative_face/chernoff_faces_quarter.png\ngenerative_face/macawnivore_nose_chart_onethird.png\ngenerative_face/mike_pelletier_onethird.jpg\ngenerative_face/sobecka_perfect_creatures_onethird.jpg",
        "aspirationcaptions": "1. Although Matthias Dörfelt’s *Weird Faces* (2012) look hand-drawn, they are entirely expressed by algorithmic rules. http://www.mokafolio.de/works/Weird-Faces\n\n2. In Heather Dewey-Hagborg’s astounding *Stranger Visions* (2012), forensic 3D portraits are computed from found DNA fragments. http://deweyhagborg.com/strangervisions/\n\n3. \"Chernoff faces\" are a type of display in which multivariate data are represented by the shape, size, position and orientation of the parts of the face. From Wikipedia. https://en.wikipedia.org/wiki/Chernoff_face\n\n4. *Nose Chart Reference* (2014) by Macawnivore. http://macawnivore.deviantart.com/art/Nose-Chart-Reference-451870046\n\n5. In Mike Pelletier’s *Parametric Expression*, values that govern the articulation of facial models are pushed beyond their normal limits. http://mikepelletier.nl/Parametric-Expression\n\n6. In Karolina Sobecka’s *All the Universe is Full of the Lives of Perfect Creatures* (2012), the visitor puppeteers an avatar through the movements of their own face. http://www.gravitytrap.com/artwork/perfect-creatures",
        "additionalreferences": "Blas, Zach. *Facial Weaponization Suite*.\nhttps://vimeo.com/57882032\nBravi, Lorenzo et al. *Bla Bla Bla*.\nhttp://goo.gl/2w4CfC\nBorenstein, Greg. *Machine Pareidolia*.\nhttp://urbanhonking.com/ideasfordozens/2012/01/14/machine-pareidolia-hello-little-fella-meets-facetracker/\n\"Computer facial animation\". In Wikipedia. https://en.wikipedia.org/wiki/Computer_facial_animation\nDarwin, Charles. *The Expression of Emotions in Man and Animals*. http://darwin-online.org.uk/\n\"Facial Action Coding System\". In Wikipedia. https://en.wikipedia.org/wiki/Facial_Action_Coding_System\nLevin, Golan and Lieberman, Zachary. *Re:Face*. http://www.flong.com/projects/reface/\nLieberman, Zachary. *Masquelacara*. https://www.instagram.com/p/BDxsVZ0JNpm/\nMcDonald, Kyle. *Face as Interface*. https://github.com/kylemcdonald/AppropriatingNewTechnologies/wiki/Week-2\nMcDonald, Kyle. *FaceOSC*. https://github.com/kylemcdonald/ofxFaceTracker\nMcDonald, Kyle and Castro, Arturo. *Face Substitution*. https://vimeo.com/29348533\nMunari, Bruno. *Design as Art*. (1971)\nPerlin, Ken. *FaceDemo* (Java Applet).\nhttp://mrl.nyu.edu/~perlin/facedemo/"
    },
    {
        "in": 1,
        "titles": "Parametric Alphabet",
        "shortdescription": "Structuring letterforms with a common model",
        "level": "Intermediate",
        "tagsstem": "data structures, parametric design, interpolation",
        "tagsarts": "dynamic typography, letterforms",
        "learningobjectives": "•  Use arrays to store geometric data\n•  Apply principles of meta-design to fonts\n•  Conceive and appraise graphical concepts for dynamic typography\n•  Manipulate and/or animate letterforms computationally",
        "brief": "Create a typeface (using any graphic primitives you prefer), such that all of the letters of the alphabet are structured by the same underlying graphic logic. For example, you might design an alphabet in which every letter is exclusively constructed from 3 arcs, or from 4 rectangles, or from a small grid of squares. After you have designed all of your letters, typeset the entire alphabet on a single canvas so that it can be seen at a glance.\n\nAn essential technical goal is for you to store descriptive parameters for your letters in some kind of array or object-oriented data structure, and then create a single function which renders any requested letter from this data. If you're writing individual functions to draw each letter, you're doing something wrong.",
        "variations": "•  Typeset a carefully chosen word that has a special relationship to your letterforms’ design. \n•  Give your letters inherently unstable properties. Animate your letterforms by deflecting their control points with a sinusoidal wiggle, Perlin noise, or real-time interactivity. \n•  With a single character onscreen, make it possible to animate the transitions between letters, such that any letter can smoothly morph into any other. Pressing a key should initiate an animated transition (of approximately a second's duration) from the previous letter to the next desired letter. *Instructors: for introductory students, it may be helpful to provide a template for transitioning between letterforms.* ",
        "advancedstudents": "•  Consider a design in which letters are traces deposited by moving particles—whose paths are affected by forces from different spatial configurations of attractors and repulsors.\n•  A \"forced aligner\" is a computer program that takes audio files and their transcripts, and returns extremely precise timing information. Using your typeface and a forced aligner (such as *Gentle* by Ochshorn & Hawkins), create time-synced dynamic typography that not only synchronizes perfectly with a speech file, but also responds parametrically to the sound of the speaker's voice.",
        "makingitmeaningful": "Extending from Adrian Frutiger's Univers (1954), Donald Knuth's computational MetaFont (1977), and Adobe's \"Multiple Master\" fonts (1994), it has become increasingly common practice to design highly adaptable type *systems* that go far beyond the rigid limits of static type *faces*. Peter Biľak writes: \"Prior to Univers, type designers concerned themselves with the relationships between letters of the same set, how an 'A' is different from a 'B'. Univers goes beyond the quest to design individual letters, attempting instead to create a system of relationships between different sets of shapes which share distinctive parameters.\" \n\nThe creative value of constraints is foregrounded in this prompt. Restricted to designing letterforms with shared parameters, students are compelled to think with modularity, economy and ingenuity about shapes whose variety and complexity they often take for granted. The expressive potential for contingent, interactive and subtly *time-varying* form systems should not be overlooked. Ask each student to name the letters where their structuring pattern succeeds best and fails hardest. Compare and contrast. ",
        "titlegray": 0,
        "fullpageimage": "alphabet/pashenkov_alphabot_fullpage.png",
        "layout": 21,
        "image": "alphabet/huang_typeface_onethird.jpg\nalphabet/lu_alphabet_twothirds.png\nalphabet/cho_typemenot_quarter.png\nalphabet/nimoy_davenport_quarter.jpg",
        "aspirationcaptions": "1. Nikita Pashenkov's *Alphabot* (2000) is a Transformer-like robot \"that communicates with humans by changing its shape to form characters of the English alphabet.\" Each letter can fold into any other. http://tdctokyo.org/eng/?award=01_nikita-pashenkov\n\n2. Mary Huang's *Typeface2: a Typographic Photobooth* (2010) is a font whose parameters are governed by signals from a real-time face-tracker. http://www.creativeapplications.net/processing/typeface-processing/\n\n3. David Lu's *Letter 3* (2002) presents an interactive alphabet whose letters are formed by manipulating the control points of a single springy curve. Each letter can smoothly transform into any other. http://velluminous.org/portfolio/a/demos/letter3/\n\n4. In Peter Cho's classic *Type Me, Type Me Not* (1997), each letter is constructed from two \"Pac-Man\" filled arcs, and is represented by just 10 numbers. http://acg.media.mit.edu/people/pcho/typemenot/index.html\n\n5. As keys are pressed in Josh Nimoy's *Robotic Type* systems (2004), mechanical elements shift into place, forming the requested characters. http://cdn.jtn.im/robotictype/",
        "additionalreferences": "Biľak, Peter. *Designing Type Systems* (2012). https://www.typotheque.com/articles/designing_type_systems\nFlückiger, Michael and Kunz, Nicolas. *LAIKA: a dynamic typeface* (2009). http://laikafont.ch/index.html\nHofstadter, Douglas. *Fluid Concepts and Creative Analogies.* (1995).\nJones, C.S. \"What Is Algorithmic Typography?\" (2015). https://crmrkt.com/jyVEO\nKnoth, Christoph. *Computed Type*.\nhttps://vimeo.com/60651938\nKnuth, Donald. \"A Punk Meta-Font\". *TUGboat*, Volume 9 (1988). http://www.tug.org/TUGboat/Articles/tb09-2/tb21knut.pdf\nKnuth, Donald. \"The Concept of a Meta-Font\" (1982). *Visible Language* 16. http://www.zigzaganimal.be/elements/the-concept-of-metafont.pdf\nLehni, Jürg, et al. *Lego Font Creator* (2001). http://lineto.com/The+Projects/Nicolai.+A+New+Font./\nLehni, Jürg. *Typeface as Programme* (2009). https://www.typotheque.com/articles/typeface_as_programme\nMadsen, Rune. *Printing Code: Typography.* http://printingcode.runemadsen.com/lecture-typography/\nMaeda, John. *Tangram Font* (1993). http://www.maedastudio.com/1997/imda/index.php\nShim, Kyuha. *Code & Type.* http://code-type.com/about/",
        "notes": "“To create a typeface that is easily malleable in the computational medium, the constituent shapes must be reduced to compact numerical forms.”\n— John Maeda, 2000\n\n“By this art you may contemplate the variation of the 22 letters…”\n— Jorge Luis Borges, The Library of Babel (La biblioteca de Babel), 1941 "
    },
    {
        "in": 1,
        "titles": "Generative Landscape",
        "shortdescription": "World-making and terraforming",
        "level": "Intermediate",
        "tagsstem": "Probability, randomness, fractals, Perlin noise",
        "tagsarts": "landscape, virtual environment",
        "learningobjectives": "•  Apply principles of generative design to terrain, scenery, and worlds of their own imagination.\n•  Understand how to bias randomness in order to carefully regulate probabilities.",
        "brief": "Write a program which presents an imaginative, ever-changing \"landscape\". Populate your landscape with features that are suitable for your concept: perhaps trees, buildings, vehicles, animals, people, food items, body parts, hairs, seaweed, space junk, zombies etc.\n\nGive consideration to the *depth of variation* in your landscape: after how much time does your landscape become predictable? How might you forestall this as long as possible? How can you generate a landscape which is both consistent and engaging?\n\nConsider: foreground, middleground, and background “layers”; variation at the macro- scale, meso-scale, and micro-scale; natural and human-made features; utopia, dystopia, and heterotopia; and the potential for *surprise*, through the placement of *infrequent* features.",
        "variations": "•  Give consideration to the manner in which the landscape moves past the “camera”. For example, it might appear to scroll by (as if you were looking out the window of a train); or approach from a first-person point of view (as if you were driving, or riding a roller coaster), or slide underneath (as if you were looking out of a glass-bottomed airplane). Consider too a moving or even *roving* camera, capable of rotation as well as translation. \n•  Your project could depict an outside scene, an interior one (such as objects on a conveyor belt), or an altogether dreamlike one. \n•  Consider experimenting with 3D (as in noise terrains); 2D (as in side-scrolling video games); “2.5D” layered spaces; orthographic views; or even nonlinear, non-Cartesian geometries.\n•  Give consideration to *sound*, and the possibilty for audiovisual synchronicities (as in *Guitar Hero*).\n•  Make an autonomous creature, vehicle, or other character traverse your landscape.\n•  Implement features in your landscape which grow, evolve or erode over time.\n•  Populate your landscape with one or more of the “three verticals” (people, trees, and buildings): according to Jungian psychology, the defining psychological features of landscapes.",
        "makingitmeaningful": "We are a migrant species, instilled with a *wanderlust* that continually clamors for new horizons. Before the modern era of mobility, landscape paintings were often the primary means by which people could visualize and escape, in their minds, to faraway lands. \n\nToday, eight-year olds trade “seeds” for favored Minecraft worlds, and computer-generated environments have become commonplace in video games, where the algorithmic generation of novel landscapes is an economic necessity for inexhaustible play. For the meta-designer and artist-programmer, there is assuredly something godlike about calling forth world upon world. It is probably not a coincidence that the first all-CGI sequence in a feature film depicted the synthesis of an entire planet, in the triumphant “Genesis Sequence” of *Star Trek II* (1982).\n\nThis assignment asks the student to write the rules that bring forth a world from their imagination. But it could equally well ask them to create an accurate computational representation of a very real place—and to generate “more” of it. ",
        "titlegray": 255,
        "fullpageimage": "landscape/mandelbrot_voss_fullpage.jpg",
        "layout": 1,
        "image": "landscape/tarbell_substrate_quarter.jpg\nlandscape/nullpointer_landscape_quarter.jpg\nlandscape/pipkin_mirrorlake_quarter.png\nlandscape/kyttenjanae_lonelyplanets_quarter.png",
        "aspirationcaptions": "1. \"Fractional noise\" mountains (c. 1982) developed by Benoît Mandelbrot and Richard F. Voss at IBM were a landmark in mathematical terrain synthesis. http://www.wired.com/2013/01/mandelbrot-images/\n\n2. In Jared Tarbell's classic *Substrate* (2003), simulated urban tectonics arise from elementary principles of accretion, branching, and feedback. http://www.complexification.net/gallery/machines/substrate/\n\n3. Tom Betts, also known as Nullpointer, developed a \"British Countryside Generator\" for the Big Robot game, *Sir, You Are Being Hunted.* https://www.flickr.com/photos/tomnullpointer/albums/72157644542312590/\n\n4. Katie Rose Pipkin generates barren flowerpot landscapes in her poetic and mysterious browser work, *Mirror Lake* (2015). http://katierose.itch.io/mirrorlake\n\n5. Kristyn Janae Solie's *Lonely Planets* (2013) is a stylized 3D terrain that shifts between minimalism and psychedelia. The work was created for Casey Reas' undergraduate course, *Live Cinema through Creative Coding*. http://www.kyttenjanae.com/",
        "additionalreferences": "Akten, Memo and Berio, Daniel. *Bozork Quest* (2013). https://vimeo.com/113106061\nBeddard, Tom. *Surface Detail* (2011). http://sub.blue/surface-detail\nBrown, Daniel. *Travelling by Numbers* (2016). http://flic.kr/s/aHskyNR2Tz\nField.io. *Interim Camp* (2009). http://www.field.io/project/interim-camp/\nGeilfus, Simon. *Muon glNext* (2014). https://vimeo.com/108393262\nHart, Vi et al. *Float* (2015). https://vimeo.com/147908916\nHodgin, Robert. *Audio-generated landscape* (2008). https://vimeo.com/2094557\nHoff, Anders. *Isopleth* (2015). http://inconvergent.net/isopleth/\nLemercier, Joanie. *Landforms* (2014). http://joanielemercier.com/landforms/\nMcCormack, Jon. *Morphogenesis Series* (2001). http://jonmccormack.info/\nMcKay, Joe. *Sunset Solitaire* (2010). http://www.joemckaystudio.com/sunset.php\nMolnar, Vera. *Variations St. Victoire* (1989-1996). http://veramolnar.com/\nPlanetside Software. *Terragen* (2008-). http://www.planetside.co.uk/\nQuayola, Davide. *Pleasant Places* (2015). http://www.quayola.com/pleasant-places/\nZawada, Jonathan. *Over Time* (2011). http://www.zawada.com.au/2013/01/02/over-time/"
    },
    {
        "in": 1,
        "titles": "Clock",
        "shortdescription": "Representing time",
        "level": "All levels",
        "tagsstem": "timekeeping, measurement",
        "tagsarts": "time, rhythm, dynamism, animation",
        "learningobjectives": "•  Become acquainted with the history of systems and devices for timekeeping\n•  Devise technologies and graphic concepts for representing time that go beyond conventional methods of visualization and mediation\n•  Refine craft skills in the use of programming to control shape, color, form, and motion\n",
        "brief": "Design a ‘visual clock’ that displays a novel or unconventional representation of the time. It is not essential that the time of day be literally readable from it, but your clock should appear different at all times of the day, and it should repeat its appearance every 24 hours (or other relevant cycle).\n\nYou are encouraged to seriously question basic assumptions about how time is mediated and represented. Ponder things like biological time (chronobiology), ultradian and infradian rhythms, solar and lunar cycles, celestial time, decimal time, metric time, geological time, historical time, psychological time, and subjective time. Inform your design by reading about the history of timekeeping systems and devices, and their transformative effects on society.",
        "variations": "•  Feel free to experiment with any of the tools at your disposal, including shape, color, transparency, sound, dynamism, and physical actuation. Reactivity to the cursor is optional. \n•  You are strictly prohibited from using Roman, Arabic, or Chinese numerals. However, you may still make the time literally readable through other means, such as by visualizing numeric bit patterns, or presenting countable graphic elements.\n•  Your code will need to access the current hour(), minute(), second(), and potentially the millis(). However, you could also access the day(), month(), and year(), for a clock which changes over the seasons or human lifespans.\n•  Develop your clock for a portable or wearable device, such as a mobile phone, smart watch, fitness tracker, or other standalone computer with a small display. Consider incorporating data from your device’s other sensors into your design, such as a user’s image, movements, body temperature, heartbeat, etc.\n•  Free yourself from the desktop or laptop screen, and design your clock for a context of your own choosing. If you could place your clock anywhere, where would it be? On the side of a building? As a piece of furniture? In someone’s pocket? Or as a digital tattoo? Include a drawing, rendering or other mockup showing your clock as you imagine it *in situ.* ",
        "makingitmeaningful": "Attempts to mark time stretch back many thousands of years, with some of the earliest timekeeping technologies being gnomons, sundials, water clocks, and lunar calendars. Even today’s standard representation of time, with hours and minutes divided into 60 parts, is a legacy inherited from the ancient Sumerians, who used a sexagesimal counting system.\r\r\n \nThe history of timekeeping is the history of a still unfolding relationship between technological developments and a social pressure for greater precision, accuracy, and synchronization. Every increase in our ability to precisely measure time has had a profound impact on our mastery of science, agriculture, navigation, communications, and always, warcraft.\r\r\n \nDespite the widespread adoption of machinic \nstandards, there are many other ways to understand time. Psychological time contracts and expands with attention; biological cycles affect our moods and behavior; geological or planetary rhythms can span millenia. During the early 20th century, Einstein’s revelations in theoretical physics again reformed our understanding of time, proposing that it is not a constant linear stream but is relative to the position from where it is measured, a surprising return to the significance of the observer.",
        "titlegray": 0,
        "fullpageimage": "defaults/default_fullpage_666x522.jpg",
        "layout": 1,
        "image": "defaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg",
        "aspirationcaptions": "John Maeda, Reactive Books, (1994-1999). Online: https://www.youtube.com/watch?v=nA_UTUvC4h8 \nGolan Levin, Banded Clock, (1999). Online: http://www.flong.com/storage/experience/clock/ \nJack Hughes, Color clock (2011). Online: http://thecolourclock.co.uk/\nMonika, All the Minutes (2014). Online: https://twitter.com/alltheminutes \nKatie Paterson, Time Pieces (2014). Online: http://www.katiepaterson.org/timepieces/ ",
        "additionalreferences": "Drucker, Johanna. \"Timekeeping\". In *Graphesis: Visual Forms of Knowledge Production.* Harvard, 2014.\nFoer, Joshua. \"A Minor History of Time Without Clocks\". *Cabinet Magazine,* Issue 29, 2008.\nGroom, Amelia. *Time (Documents of Contemporary Art.* MIT Press, 2013.\nTortorello, Michael. \"Five Minutes to Moonflower\". *The New York Times,* 1/28/2015.",
        "notes": "John Maeda, Reactive Books (1994-1999). \nGolan Levin, Banded Clock (1999).\nJack Hughes, Color clock (2011). \nMonika, All the Minutes (2014). \nKatie Paterson, Time Pieces (2014)."
    },
    {
        "in": 1,
        "titles": "Browser Extension",
        "shortdescription": "Lens for the internet",
        "level": "Intermediate",
        "tagsstem": "web, internet, browser, extension, add-on",
        "tagsarts": "detournment, intervention, network, interactivity",
        "learningobjectives": "•  Develop an understanding of basic website structure and functionality.\n•  Develop an understanding of basic browser functionality.\n•  Creation of a browser based creative intervention.",
        "brief": "Build a browser extension that either alters the appearance of the internet or augments or estranges the browsing experience in a poetic or critical way. A browser extension is a software intervention that alters the behavior of a browser application. Extensions can do things like change the way specific online content appears, add additional content layers, redirect the audience to different URLs or change browser behaviors. At the time of writing both Chrome and Firefox offered thorough documentation for the development of extensions so it is recommended to choose either of these browsers to work with.\n",
        "variations": "Students who are inexperienced with web design can be introduced to online interventions through the preliminary exercise of modifying website code in the console of the browser. The styling and content of a page can be edited temporarily by changing the css or html of a page directly or algorithmically by adding lines of javascript. This introductory step introduces students to the console, and will help them to develop an understanding of the basic structure and function of a website. Their experiments at this stage can scaffold the creation of an extension. \nThis assignment brief can also be tailored to be more constrained by asking students to carry out a specific intervention such as a text based modification, an image find and replace, a style based css change or a content augmentation, where an extra layer of information is added to webpages, usually through the use of an external API or dataset.. Requiring students to submit their extensions to a public repository like the Chrome store can also be included as a final step for publishing this assignment. ",
        "advancedstudents": "Multiuser extensions. Use of data from an external API.",
        "makingitmeaningful": "Like a window mediates our view of the physical world, the browser mediates our experience of the internet. It is a small but critical piece of infrastructure in the complex system that underlies all of our online activities. Building a creative extension therefore, is an opportunity for intervening at either a systems, protocol or content level, or a combination. Software studies texts such as the now canonical Protocol by Alex Galloway offer ways to approach the internet from the perspective of infrastructure and protocol, opening the way for creative interventions that modify or reveal the browser's function and the contruction of the web.\n\nThis assignment can be conceptually scaffolded with ideas and strategies drawn from the history of conceptual art. Online interventions that manipulate everyday web content extend ideas from the Situationalists who were working in the 1950s and 1960s, into an online context. Situationalist strategies such as detournment and derive aim to estrange the mundane and everyday experience of life and are conceptually prescient to contemporary examples of extensions that modify user navigation across the web such as We See in Every Direction by Jonas Lund, or those that find and replace specific content like Rose Colored Window by Katie Rose Pipkin. Extensions can also be tools for activism and critical and tactical art. By layering additional information onto the browsing experience, they can reveal and explicate otherwise obscure relationships and connections. Examples of this include the Sunlight Foundation's Influence Explorer, Allison Burtch's Internet Illuminator, BookIndy's Browse Amazon, Buy Local.",
        "fullpageimage": "defaults/default_fullpage_666x522.jpg",
        "aspirationcaptions": "1. Steve Lambert's Add Art (2008) replaces online advertisements with curated art exhibitions.\n2. Jonas Lund's, We See in Every Direction (2013). http://ineverydirection.net/\n3. Julian Oliver and Daniil Vasiliev (2011), News Tweak https://julianoliver.com/output/newstweek\n4. Melanie Hoff, Decodelia. https://melanie-hoff.com/DECODELIA/\n5. Joanne Mcneil, Emotional Labor. http://www.joannemcneil.com/ga®llery/emotional-labor/\n\n",
        "additionalreferences": "Debord, Guy. \"A User’s Guide to Détournement (1).\" (1956).\nKen Goldsmith, 2011, Uncreative Writing, Chapter 2, Language as material.\nKatie Rose Pipkin Rose Colored Window (2015).\nAllison Burtch Internet Illuminator. http://www.allisonburtch.net/illuminator/\nDavid Nicholls, BookIndy, Browse Amazon, Buy Independent addon. http://bookindy.com/\nDan Phiffer and Mushon Zer Aviv, Shiftspace (2007). \nSam Lavigne and Tega Brain, The Intergovernmental Panel on Capitalism, (2015). http://intergovernmentalpaneloncapitalism.org/\nThe New York Time Special Edition. http://nytimes-se.com/\nSunlight Foundation, Influence Explorer (2013).\nFB Graffeti by Joel Simon. http://www.joelsimon.net/fb-graffiti.html\nLauren Mccarthy and Kyle Mcdonald. Us+. http://lauren-mccarthy.com/us\n"
    },
    {
        "in": 1,
        "titles": "Virtual Creature",
        "shortdescription": "Create an organism that lives on the screen",
        "level": "Intermediate ",
        "tagsstem": "object-orientated, class",
        "tagsarts": "artifical life, motion, animation",
        "learningobjectives": "•  Develop an application using object orientated programming techniques.\n•  To write functions that produce motion.\n•  Use of a class table.\n",
        "brief": "Design a class which displays, animates, and defines the behavior of a machine or organism. Give your invention a goal (e.g. finding other creatures, searching for food, climbing the screen) and have it react when it reaches its goal. Display your class outline table as a comment in the code. Show the fields and datatypes, the methods and their return values.",
        "variations": "Pair of creatures - interesting diads. Array of creatures, each with different behaviors, motion based on emotion",
        "makingitmeaningful": "The simulation of artifical life and life systems has a long history in computational artforms. From canonical examples of computer programs such as  Game of Life",
        "titlegray": 0,
        "fullpageimage": "defaults/default_fullpage_666x522.jpg",
        "layout": 1,
        "image": "defaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg\ndefaults/default_quarter_282x210.jpg",
        "aspirationcaptions": "Single Cell, Golan Levin and friends (2002). Online: http://www.singlecell.org/singlecell.html\nDouble Cell, Golan Levin and friends (2001). Online: http://www.singlecell.org/ \nMorphogenesis Series, Jon Mccormack (2002). Online: http://jonmccormack.info/~jonmc/sa/artworks/morphogenesis-series/\nInteractive Plant Growing, Laurent Mignonneau & Christa Sommerer (1992). Online: http://www.interface.ufg.ac.at/christa-laurent/WORKS/FRAMES/FrameSet.html \nLife Writer, Laurent Mignonneau & Christa Sommerer (2006): Online: http://www.interface.ufg.ac.at/christa-laurent/WORKS/FRAMES/FrameSet.html \nDelicate Boundaries, Chris Sugrue (2007). Online: http://csugrue.com/delicateboundaries/ \nKarl Sims, Evolved Virtual Creatures (1994), https://archive.org/details/sims_evolved_virtual_creatures_1994 .",
        "additionalreferences": "\n",
        "notes": "Single Cell, Golan Levin and friends (2001). \nDouble Cell, Golan Levin and friends (2002).\nMorphogenesis Series, Jon Mccormack (2002).\nInteractive Plant Growing, Laurent Mignonneau & Christa Sommerer (1992).\nLife Writer, Laurent Mignonneau & Christa Sommerer (2006).\nDelicate Boundaries, Chris Sugrue (2007). \nKarl Sims, Evolved Virtual Creatures (1994)."
    }
  
   
]