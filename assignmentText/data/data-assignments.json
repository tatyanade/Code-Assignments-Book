[
    {
        "in": 1,
        "titles": "Iterative Pattern (Wallpaper)",
        "section": "Processuality",
        "shortdescription": "Generating a texture or textile design\n",
        "level": "All levels ",
        "tagsstem": "iteration, functional abstraction, coordinates, graphics primitives, graphics transforms, tesselation, symmetries",
        "tagsarts": "pattern, texture, rhythm, shape, curves",
        "learningobjectives": "•  Develop an understanding of drawing functions and the Cartesian coordinate system\n•  Use functional abstraction to encapsulate the code for a modular design element\n•  Gain experience generating high-resolution raster and/or vector designs",
        "brief": "Write code to generate a tiling pattern or textural composition, such as for wallpaper or fabric. Give consideration to aesthetic issues like symmetry, rhythm, color; detail at multiple scales; precise control of shape; and the balance between organic and geometric forms. Your pattern should be designed so that it could be infinitely tiled or extended. Design something you would actually like to put on the walls of your home, or which you could imagine yourself actually wearing. Export your pattern in a high-resolution format, and print it as large as possible. Projects will be critiqued at the pin-board. Remember to sketch first.",
        "variations": "•  Experiment with 2D graphics transformations, such as rotate(), scale(), and mirror reflections.\n•  Use *nested iteration* to develop 2D rhythms or other gridlike visual structures.\n•  Create a *helper function* to encapsulate the way in which a complex visual element (such as a flower, animal, fruit, fleur-de-lys, etc.) is rendered throughout your design.\n•  Strictly using code, reproduce a pre-existing textile or wallpaper design.\n•  Make a kaleidoscope, by incorporating a photographic image or video feed into the pattern.\n•  Have your pattern printed on a real textile, wrapping paper, etc. by an online fabrication service such as Spoonflower, Constrvct, or Print All Over Me. Consider other output devices for realizing your pattern, such as computer-controlled laser cutters, knitting machines, and lace-making services.",
        "advancedstudents": "Think beyond the rectangular grid. Investigate \"wallpaper group\" symmetries; convex uniform tilings; aperiodic tiles; texture synthesis and re-synthesis. Experiment with the use of particle systems for placing elements.",
        "makingitmeaningful": "Pattern is the starting point from which we perceive and impose order in the world. The art of visual pattern-making is as old as humankind itself, and countless examples abound, whether functional, decorative or expressive, in forms like mosaics, calendars, tapestry, quilting, jewelry, calligraphy, furniture, architecture, and more. There is an intimate connection between pattern design, visual rhythm, geometry, mathematics, and iterative algorithms; this prompt invites students to hone their understanding of these relationships in purely formal terms. Realizing a design *physically*, especially through digital printing or fabrication in an unusual material or size, can be a watershed moment of synthesis for students who crave \"something real\". ",
        "titlegray": 255,
        "fullpageimage": "wallpaper/todo_spamghetto_2_fullpage.jpg",
        "layout": 11,
        "image": "wallpaper/polya_tallhalf.png\nwallpaper/marrakech_tiles_onethird.jpg\nwallpaper/reas_pill_a_day_onethird.jpg\nwallpaper/gondek_gallifreyan_onethird.png",
        "aspirationcaptions": "1. In *Spamgetto* (2009), the Italian design agency Todo presents wallpaper whose design is computationally generated from thousands of spam emails. https://www.flickr.com/photos/todotoit/sets/72157616412434905/\n\n2. George Pólya's illustrations (1924) of the seventeen periodic plane symmetry groups had a profound influence on the algorithmic patternmaking of M.C. Escher.\n\n3. Zellige terracotta tiles in Marrakech (17th century) form edge-to-edge, regular and other tessellations. Photo by Ian Alexander, 2000. From Wikipedia. https://en.wikipedia.org/wiki/Tessellation.\n\n4. Casey Reas's *One Non-Narcotic Pill A Day* (2013) presents a dynamic collage pattern generated from a video recording.\n\n5. Alison Gondek, an introductory programming student at CMU, used JavaScript to create this pattern inspired by the “Circular Gallifreyan” language from *Doctor Who*.",
        "additionalreferences": "\"Aperiodic Tiling\". In Wikipedia. https://en.wikipedia.org/wiki/Aperiodic_tiling\nBailey, David. *David Bailey's World of Escher-like Tessellations*. http://www.tess-elation.co.uk/\nGrünbaum, B., & Shephard, G. C. (1987). *Tilings and patterns*. Freeman.\nJones, O. (1868). *The grammar of ornament*. B. Quaritch.\nSchattschneider, D. \"The Mathematical Side of M. C. Escher,\" in *AMS Notices* 57: 706-718, 2010. http://www.ams.org/journals/notices/201006/rtx100600706p.pdf\n\"Texture Synthesis\". In Wikipedia. https://en.wikipedia.org/wiki/Texture_synthesis\n\"Wallpaper Collection\", Historic New England. http://www.historicnewengland.org/collections-archives-exhibitions/collections-access/highlights/wallpaper\n\"Wallpaper Groups\". In Wikipedia. https://en.wikipedia.org/wiki/Wallpaper_group\n\nAlso see works by: Casey Reas, Marius Watz, Lia, Jonathan McCabe, Mitchell Whitelaw, Tina Frank, Joshua Davis, Dave Bollinger, Holger Lippmann."
    },
    {
        "in": 1,
        "titles": "Face Generator",
        "section": "Processuality",
        "shortdescription": "Drawing parametric faces",
        "level": "All levels",
        "tagsstem": "parametric design, constrained randomness, graphics primitives, variables",
        "tagsarts": "portraiture, physiognomy, character design, puppets, avatars",
        "learningobjectives": "•  Develop familiarity with drawing functions and parametric form\n•  Apply generative principles to expressive character design\n•  Develop skills as a meta-designer",
        "brief": "Write code to create a face design which is parameterized by at least three dimensions of variability, but preferably more. For example, you might have variables that specify the size, position, color, or other visual characteristics of the eyes, nose, and mouth. The variations in these features may be used to alter the face’s expression (happy, sad, angry, etc.); the face’s identity (John, Mary, etc.); and/or the face’s species (cat, monkey, zombie, alien, etc.). Give consideration to *continuous* parameters (such as nose size or eyebrow position), versus *discrete* parameters (such as the presence of piercings, or the number of eyeballs). Your system should generate a new face whenever the user clicks the mouse.",
        "variations": "•  Consider whether your faces are 2D or 3D, and whether they are generated in frontal, profile, and/or three-quarters view.\n•  Give special consideration to controlling the precise *shape* of face parts, such as the curves of the nose, chin, ears, and jowls.\n•  Consider characteristics like skin color, stubble, hairstyle, blemishes, interpupillary distance, facial assymmetry, cephalic index, prognathism, etc.\n•  Use your software to generate a deck of collectible trading cards (like Pokémon or baseball cards), featuring a group of imaginary monsters. Print out the cards.\n•  For visualization students, try using actual multivariate data as the basis for generating new faces, rather than randomness.\n•  Add functionality to your face so that it responds to audio or microphone input. \n•  This project can be used as a follow-up to a preliminary exercise: using code to render a static self-portrait.",
        "advancedstudents": "Create a parameterized facial puppet which is controlled by signals from a real-time face tracker (such as *FaceOSC*). Practice a brief monologue and record a screen-captured video performance with your avatar.",
        "makingitmeaningful": "Humans are equipped with an exquisite sensitivity to faces. From infancy we easily recognize faces, and can detect very subtle shifts in facial expressions, often being able to discern the slightest change in mood and sincerity in ways that remain impossible for computers. From faces we are also readily able to identify family resemblances, or \"strangers\" in crowds, and we are transfixed by the ways in which the lines on a face can reveal a person's life history. Kyle McDonald writes that \"faces are so important that the impairment of our face-processing ability is seen as a disorder, called *prosopagnosia*, while unconsciously seeing faces where there are none is an almost universal kind of *pareidolia*.\"\n\nThis assignment draws inspiration from the “Chernoff Face\" data visualization technique, which leverages this sensitivity by using facial features to represent multivariate data. In Chernoff Faces, features such as eyes, ears, mouth and nose represent data according to their shape, size, placement and orientation. Whereas Chernoff (1973) used 18 variables to *synthesize* a face, Paul Ekman’s \"Facial Action Coding System\" uses 46 dimensions to *analyze* a facial expression, each corresponding to the action of a different facial muscle.",
        "titlegray": 0,
        "fullpageimage": "generative_face/moka_faces_1_fullpage.jpg",
        "layout": 20,
        "image": "generative_face/hdh_stranger_visions_quarter.jpg\ngenerative_face/chernoff_faces_quarter.png\ngenerative_face/macawnivore_nose_chart_onethird.png\ngenerative_face/mike_pelletier_onethird.jpg\ngenerative_face/sobecka_perfect_creatures_onethird.jpg",
        "aspirationcaptions": "1. Although Matthias Dörfelt’s *Weird Faces* (2012) look hand-drawn, they are entirely expressed by algorithmic rules. http://www.mokafolio.de/works/Weird-Faces\n\n2. In Heather Dewey-Hagborg’s astounding *Stranger Visions* (2012), forensic 3D portraits are computed from found DNA fragments. http://deweyhagborg.com/strangervisions/\n\n3. \"Chernoff faces\" are a type of display in which multivariate data are represented by the shape, size, position and orientation of the parts of the face. From Wikipedia. https://en.wikipedia.org/wiki/Chernoff_face\n\n4. *Nose Chart Reference* (2014) by Macawnivore. http://macawnivore.deviantart.com/art/Nose-Chart-Reference-451870046\n\n5. In Mike Pelletier’s *Parametric Expression*, values that govern the articulation of facial models are pushed beyond their normal limits. http://mikepelletier.nl/Parametric-Expression\n\n6. In Karolina Sobecka’s *All the Universe is Full of the Lives of Perfect Creatures* (2012), the visitor puppeteers an avatar through the movements of their own face. http://www.gravitytrap.com/artwork/perfect-creatures",
        "additionalreferences": "Blas, Zach. *Facial Weaponization Suite*.\nhttps://vimeo.com/57882032\nBravi, Lorenzo et al. *Bla Bla Bla*.\nhttp://goo.gl/2w4CfC\nBorenstein, Greg. *Machine Pareidolia*.\nhttp://urbanhonking.com/ideasfordozens/2012/01/14/machine-pareidolia-hello-little-fella-meets-facetracker/\n\"Computer facial animation\". In Wikipedia. https://en.wikipedia.org/wiki/Computer_facial_animation\nDarwin, Charles. *The Expression of Emotions in Man and Animals*. http://darwin-online.org.uk/\n\"Facial Action Coding System\". In Wikipedia. https://en.wikipedia.org/wiki/Facial_Action_Coding_System\nLevin, Golan and Lieberman, Zachary. *Re:Face*. http://www.flong.com/projects/reface/\nLieberman, Zachary. *Masquelacara*. https://www.instagram.com/p/BDxsVZ0JNpm/\nMcDonald, Kyle. *Face as Interface*. https://github.com/kylemcdonald/AppropriatingNewTechnologies/wiki/Week-2\nMcDonald, Kyle. *FaceOSC*. https://github.com/kylemcdonald/ofxFaceTracker\nMcDonald, Kyle and Castro, Arturo. *Face Substitution*. https://vimeo.com/29348533\nMunari, Bruno. *Design as Art*. (1971)\nPerlin, Ken. *FaceDemo* (Java Applet).\nhttp://mrl.nyu.edu/~perlin/facedemo/"
    },
    {
        "in": 1,
        "titles": "Parametric Alphabet",
        "section": "Processuality",
        "shortdescription": "Structuring letterforms with a common model",
        "level": "Intermediate",
        "tagsstem": "data structures, parametric design, interpolation",
        "tagsarts": "dynamic typography, letterforms",
        "learningobjectives": "•  Use arrays to store geometric data\n•  Apply principles of meta-design to fonts\n•  Conceive and appraise graphical concepts for dynamic typography\n•  Manipulate and/or animate letterforms computationally",
        "brief": "Create a typeface (using any graphic primitives you prefer), such that all of the letters of the alphabet are structured by the same underlying graphic logic and numeric parameters. For example, you might design an alphabet in which every letter is exclusively constructed from 3 arcs, or from 4 rectangles, or from a small grid of squares. After you have designed all of your letters, typeset the entire alphabet on a single canvas so that it can be seen at a glance.\n\nAn essential technical goal is for you to store descriptive parameters for your letters in some kind of array or object-oriented data structure, and then create a single function which renders any requested letter from this data. If you're writing individual functions to draw each letter, you're doing something wrong.",
        "variations": "•  Typeset a carefully chosen word that has a special relationship to your letterforms’ design. \n•  Give your letters inherently unstable properties. Animate your letterforms by deflecting their control points with a sinusoidal wiggle, Perlin noise, or real-time interactivity. \n•  With a single character onscreen, make it possible to animate the transitions between letters, such that any letter can smoothly morph into any other. Pressing a key should initiate an animated transition (of approximately a second's duration) from the previous letter to the next desired letter. *Instructors: for introductory students, it may be helpful to provide a template for transitioning between letterforms.* ",
        "advancedstudents": "•  Consider a design in which letters are traces deposited by moving particles—whose paths are affected by forces from different spatial configurations of attractors and repulsors.\n•  A \"forced aligner\" is a computer program that takes audio files and their transcripts, and returns extremely precise timing information. Using your typeface and a forced aligner (such as *Gentle* by Ochshorn & Hawkins), create time-synced dynamic typography that not only synchronizes perfectly with a speech file, but also responds parametrically to the sound of the speaker's voice.",
        "makingitmeaningful": "Extending from Adrian Frutiger's Univers (1954), Donald Knuth's computational MetaFont (1977), and Adobe's \"Multiple Master\" fonts (1994), it has become increasingly common practice to design highly adaptable type *systems* that go far beyond the rigid limits of static type *faces*. Peter Biľak writes: \"Prior to Univers, type designers concerned themselves with the relationships between letters of the same set, how an 'A' is different from a 'B'. Univers goes beyond the quest to design individual letters, attempting instead to create a system of relationships between different sets of shapes which share distinctive parameters.\" \n\nThe creative value of constraints is foregrounded in this prompt. Restricted to designing letterforms with shared parameters, students are compelled to think with modularity, economy and ingenuity about shapes whose variety and complexity they often take for granted. The expressive potential for contingent, interactive and subtly *time-varying* form systems should not be overlooked. Ask each student to name the letters where their structuring pattern succeeds best and fails hardest. Compare and contrast. ",
        "titlegray": 0,
        "fullpageimage": "alphabet/pashenkov_alphabot_fullpage.png",
        "layout": 9,
        "image": "alphabet/huang_typeface_onethird.jpg\nalphabet/lu_alphabet_twothirds.png\nalphabet/cho_typemenot_twothirds.jpg\nalphabet/katsumoto_mojigen_onethird.jpg",
        "aspirationcaptions": "1. Nikita Pashenkov's *Alphabot* (2000) is a Transformer-like robot \"that communicates with humans by changing its shape to form characters of the English alphabet.\" Each letter can fold into any other. http://tdctokyo.org/eng/?award=01_nikita-pashenkov\n\n2. Mary Huang's *Typeface2: a Typographic Photobooth* (2010) is a font whose parameters are governed by signals from a real-time face-tracker. http://www.creativeapplications.net/processing/typeface-processing/\n\n3. David Lu's *Letter 3* (2002) presents an interactive alphabet whose letters are formed by manipulating the control points of a single springy curve. Each letter can smoothly transform into any other. http://velluminous.org/portfolio/a/demos/letter3/\n\n4. In Peter Cho's classic *Type Me, Type Me Not* (1997), each letter is constructed from two \"Pac-Man\" filled arcs, and is represented by just 10 numbers. http://acg.media.mit.edu/people/pcho/typemenot/index.html\n\n5. In Yuichiro Katsumoto's *Mojigen & Sujigen* systems (2016), electromechanical elements shift into place, forming the requested characters. http://www.katsumotoy.com/mojisuji",
        "additionalreferences": "Biľak, Peter. *Designing Type Systems* (2012). https://www.typotheque.com/articles/designing_type_systems\nFlückiger, Michael and Kunz, Nicolas. *LAIKA: a dynamic typeface* (2009). http://laikafont.ch/index.html\nHofstadter, Douglas. *Fluid Concepts and Creative Analogies.* (1995).\nJones, C.S. \"What Is Algorithmic Typography?\" (2015). https://crmrkt.com/jyVEO\nKnoth, Christoph. *Computed Type*.\nhttps://vimeo.com/60651938\nKnuth, Donald. \"A Punk Meta-Font\". *TUGboat*, Volume 9 (1988). http://www.tug.org/TUGboat/Articles/tb09-2/tb21knut.pdf\nKnuth, Donald. \"The Concept of a Meta-Font\" (1982). *Visible Language* 16. http://www.zigzaganimal.be/elements/the-concept-of-metafont.pdf\nLehni, Jürg, et al. *Lego Font Creator* (2001). http://lineto.com/The+Projects/Nicolai.+A+New+Font./\nLehni, Jürg. *Typeface as Programme* (2009). https://www.typotheque.com/articles/typeface_as_programme\nMadsen, Rune. *Printing Code: Typography.* http://printingcode.runemadsen.com/lecture-typography/\nMaeda, John. *Tangram Font* (1993). http://www.maedastudio.com/1997/imda/index.php\nNimoy, Josh. *Robotic Type* (2004). http://cdn.jtn.im/robotictype/\nShim, Kyuha. *Code & Type.* http://code-type.com/about/",
        "notes": "“To create a typeface that is easily malleable in the computational medium, the constituent shapes must be reduced to compact numerical forms.”\n— John Maeda, 2000\n\n“By this art you may contemplate the variation of the 22 letters…”\n— Jorge Luis Borges, The Library of Babel (La biblioteca de Babel), 1941 "
    },
    {
        "in": 1,
        "titles": "Generative Landscape",
        "section": "Processuality",
        "shortdescription": "World-making and terraforming",
        "level": "Intermediate",
        "tagsstem": "probability, randomness, fractals, Perlin noise",
        "tagsarts": "landscape, virtual environment",
        "learningobjectives": "•  Apply principles of generative design to terrain, scenery, and worlds of their own imagination.\n•  Understand how to bias randomness in order to carefully regulate probabilities.",
        "brief": "Write a program which presents an imaginative, ever-changing \"landscape\". Populate your landscape with features that are suitable for your concept: perhaps trees, buildings, vehicles, animals, people, food items, body parts, hairs, seaweed, space junk, zombies etc.\n\nGive consideration to the *depth of variation* in your landscape: after how much time does your landscape become predictable? How might you forestall this as long as possible? How can you generate a landscape which is both consistent and engaging?\n\nConsider: foreground, middleground, and background “layers”; variation at the macro- scale, meso-scale, and micro-scale; natural and human-made features; utopia, dystopia, and heterotopia; and the potential for *surprise*, through the placement of *infrequent* features.",
        "variations": "•  Give consideration to the manner in which the landscape moves past the “camera”. For example, it might appear to scroll by (as if you were looking out the window of a train); or approach from a first-person point of view (as if you were driving, or riding a roller coaster), or slide underneath (as if you were looking out of a glass-bottomed airplane). Consider too a moving or even *roving* camera, capable of rotation as well as translation. \n•  Your project could depict an outside scene, an interior one (such as objects on a conveyor belt), or an altogether dreamlike one. \n•  Consider experimenting with 3D (as in noise terrains); 2D (as in side-scrolling video games); “2.5D” layered spaces; orthographic views; or even nonlinear, non-Cartesian geometries.\n•  Give consideration to *sound*, and the possibilty for audiovisual synchronicities (as in *Guitar Hero*).\n•  Make an autonomous creature, vehicle, or other character traverse your landscape.\n•  Implement features in your landscape which grow, evolve or erode over time.\n•  Populate your landscape with one or more of the “three verticals” (people, trees, and buildings): according to Jungian psychology, the defining psychological features of landscapes.",
        "makingitmeaningful": "We are a migrant species, instilled with a *wanderlust* that continually clamors for new horizons. Before the modern era of mobility, landscape paintings were often the primary means by which people could visualize and escape, in their minds, to faraway lands. \n\nToday, eight-year olds trade “seeds” for favored Minecraft worlds, and computer-generated environments have become commonplace in video games, where the algorithmic generation of novel landscapes is an economic necessity for inexhaustible play. For the meta-designer and artist-programmer, there is assuredly something godlike about calling forth world upon world. It is probably not a coincidence that the first all-CGI sequence in a feature film depicted the synthesis of an entire planet, in the triumphant “Genesis Sequence” of *Star Trek II* (1982).\n\nThis assignment asks the student to write the rules that bring forth a world from their imagination. But it could equally well ask them to create an accurate computational representation of a very real place—and to generate “more” of it. ",
        "titlegray": 255,
        "fullpageimage": "landscape/mandelbrot_voss_fullpage.jpg",
        "layout": 1,
        "image": "landscape/tarbell_substrate_quarter.jpg\nlandscape/nullpointer_landscape_quarter.jpg\nlandscape/pipkin_mirrorlake_quarter.png\nlandscape/kyttenjanae_lonelyplanets_quarter.png",
        "aspirationcaptions": "1. \"Fractional noise\" mountains (c. 1982) developed by Benoît Mandelbrot and Richard F. Voss at IBM were a landmark in mathematical terrain synthesis. http://www.wired.com/2013/01/mandelbrot-images/\n\n2. In Jared Tarbell's classic *Substrate* (2003), simulated urban tectonics arise from elementary principles of accretion, branching, and feedback. http://www.complexification.net/gallery/machines/substrate/\n\n3. Tom Betts, also known as Nullpointer, developed a \"British Countryside Generator\" for the Big Robot game, *Sir, You Are Being Hunted.* https://www.flickr.com/photos/tomnullpointer/albums/72157644542312590/\n\n4. Katie Rose Pipkin generates barren flowerpot landscapes in her poetic and mysterious browser work, *Mirror Lake* (2015). http://katierose.itch.io/mirrorlake\n\n5. Kristyn Janae Solie's *Lonely Planets* (2013) is a stylized 3D terrain that shifts between minimalism and psychedelia. The work was created for Casey Reas' undergraduate course, *Live Cinema through Creative Coding*. http://www.kyttenjanae.com/",
        "additionalreferences": "Akten, Memo and Berio, Daniel. *Bozork Quest* (2013). https://vimeo.com/113106061\nBeddard, Tom. *Surface Detail* (2011). http://sub.blue/surface-detail\nBrown, Daniel. *Travelling by Numbers* (2016). http://flic.kr/s/aHskyNR2Tz\nField.io. *Interim Camp* (2009). http://www.field.io/project/interim-camp/\nGeilfus, Simon. *Muon glNext* (2014). https://vimeo.com/108393262\nHart, Vi et al. *Float* (2015). https://vimeo.com/147908916\nHodgin, Robert. *Audio-generated landscape* (2008). https://vimeo.com/2094557\nHoff, Anders. *Isopleth* (2015). http://inconvergent.net/isopleth/\nLemercier, Joanie. *Landforms* (2014). http://joanielemercier.com/landforms/\nMcCormack, Jon. *Morphogenesis Series* (2001). http://jonmccormack.info/\nMcKay, Joe. *Sunset Solitaire* (2010). http://www.joemckaystudio.com/sunset.php\nMolnar, Vera. *Variations St. Victoire* (1989-1996). http://veramolnar.com/\nPlanetside Software. *Terragen* (2008-). http://www.planetside.co.uk/\nQuayola, Davide. *Pleasant Places* (2015). http://www.quayola.com/pleasant-places/\nZawada, Jonathan. *Over Time* (2011). http://www.zawada.com.au/2013/01/02/over-time/"
    },
    {
        "in": 1,
        "titles": "The Clock",
        "section": "Processuality",
        "shortdescription": "Representing time",
        "level": "All levels",
        "tagsstem": "measurement, data visualization",
        "tagsarts": "time, rhythm, dynamism, animation",
        "learningobjectives": "•  Become acquainted with the history of systems and devices for timekeeping\n•  Devise technologies and graphic concepts for representing time that go beyond conventional methods of visualization and mediation\n•  Refine craft skills in the use of programming to control shape, color, form, and motion",
        "brief": "Design a ‘visual clock’ that displays a novel or unconventional representation of the time. It is not essential that the time of day be literally readable from it, but your clock should appear different at all times of the day, and it should repeat its appearance every 24 hours (or other relevant cycle, if desired).\n\nYou are encouraged to seriously question basic assumptions about how time is mediated and represented. Ponder things like biological time (chronobiology), ultradian and infradian rhythms, solar and lunar cycles, celestial time, decimal time, metric time, geological time, historical time, psychological time, and subjective time. Inform your design by reading about the history of timekeeping systems and devices, and their transformative effects on society.",
        "variations": "•  Feel free to experiment with any of the tools at your disposal, including transparency, color, sound, dynamism, and physical actuation. Reactivity to the cursor is optional. \n•  You're strictly prohibited from using Roman, Arabic, or Chinese numerals. However, you may still make the time literally readable through other means, such as by visualizing numeric bit patterns, or using iteration to present countable graphic elements.\n•  Your code will need to access the current hour(), minute(), second(), and potentially the millis(). However, you could also access the day(), month(), and year(), for a clock which changes over the seasons or human lifespans.\n•  Develop your clock for a portable or wearable device, such as a mobile phone, smart watch, fitness tracker, or other standalone computer with a small display. Consider incorporating data from your device’s other sensors into your design, such as a user’s image, movements, body temperature, heartbeat, etc.\n•  Free yourself from the desktop or laptop screen, and design your clock for a context of your own choosing. If you could place your clock anywhere, where would it be? On the side of a building? As a piece of furniture? In someone’s pocket? Or as a digital tattoo? Include a drawing, rendering or other mockup showing your clock as you imagine it *in situ.* ",
        "makingitmeaningful": "Attempts to mark time stretch back many thousands of years, with some of the earliest timekeeping technologies being gnomons, sundials, water clocks, and lunar calendars. Even today’s standard representation of time, with hours and minutes divided into 60 parts, is a legacy inherited from the ancient Sumerians, who used a sexagesimal counting system.\n\nThe history of timekeeping is the history of a still unfolding relationship between technological developments and a social pressure for greater precision, accuracy, and synchronization. Every increase in our ability to precisely measure time has had a profound impact on our mastery of science, agriculture, navigation, communications, and as always, warcraft.\n\nDespite the widespread adoption of machinic standards, there are many other ways to understand time. Psychological time contracts and expands with attention; biological cycles affect our moods and behavior; geological or planetary rhythms can span millenia. In the 20th century, Einstein’s theory of relativity further upended our understanding of time, showing that it does not flow in a constant way, but rather in relation to the position from which it is measured, a possibly surprising return to the significance of the observer.",
        "titlegray": 255,
        "fullpageimage": "clock/lee_byron_fullpage_666x522.png",
        "layout": 8,
        "image": "clock/maeda_clocks_282x136.jpg\nclock/standardtime_282x136.jpg\nclock/banded_clock_282x136.jpg\nclock/lastclock-282x136.jpg\nclock/moniker_all_the_minutes_282x136.png\nclock/oscar_diaz_ink_calendar_282x136.jpg",
        "aspirationcaptions": "1. Lee Byron's *Center Clock* (2007) presents the time as countable, bouncy circles. Sixty white \"second\" circles will coalesce to form a violet \"minute\" circle, and so on. http://leebyron.com/centerclock/\n\n2. Maeda, John. *12 O’Clocks* (1996) is one of the first responses to this brief, developed in 1996-97 for Classic Mac OS.\n\n3. Formanek, Mark. *Standard Time* (2003) is a video of 70 workers building a wooden 4 x 12 m \"digital\" time display in real time. http://www.standard-time.com/index_en.php\n\n4. Levin, Golan. *Banded Clock* was created for John Maeda's Aesthetics and Computation group at MIT. Seconds, minutes and hours of the current time is shown as a series of striated bands. http://www.flong.com/projects/clock/\n\n5. Angesleva, Jussi & Ross Cooper. *Last Clock* (2002) is made from live video feed and as the hands rotate around the face of the clock they leave a trace of pixels from the camera. http://angesleva.iki.fi/art/last/\n\n6. Studio Moniker. *All the Minutes* (2014). A twitter bot retweeting mentions of the time, minute by minute. Online: https://twitter.com/alltheminutes\n\n7. Diaz, Oscar. *Ink Calendar.* (2009) uses the capillary action of ink spreading across paper to display the date.",
        "additionalreferences": "Biegert & Funk. *Qlocktwo.*\nCharity, Mitchell N. *Dot Clock,* 2001.\nDrucker, Johanna. \"Timekeeping\". In *Graphesis: Visual Forms of Knowledge Production.* Harvard, 2014.\nFoer, Joshua. \"A Minor History of Time Without Clocks\". *Cabinet Magazine,* Issue 29, 2008.\nGiffen, Daniel Craig. *Human Clock,* 2001.\nGroom, Amelia. *Time (Documents of Contemporary Art.* MIT Press, 2013.\nHillis, Danny et al. *The Clock of the Long Now.*\nHumansSince1982. *The Clock Clock.*\nLevin, Golan. *Clocks in New Media.* 2016.\nLewis, Richard. \"How Different Cultures Understand Time\". *Business Insider,* 6/1/2014.\nMarclay, Christian. *The Clock,* 2010.\nMorzier, Eric. *Horloge Tactile,* 2005.\nMulder, Sander. *Continue Time,* 2007.\nMulder, Sander. *Pong Clock,* 2005.\nNakamura, Yugo. *Industrious Clock,* 2001.\nPaterson, Katie. Time Pieces, 2014. http://www.katiepaterson.org/timepieces/\nSaqoosha. *Sonicode Clock,* 2008.\nTseng, Yen-Wen. *Hand in Hand.*"
    },
    {
        "in": 1,
        "titles": "Experimental Chat",
        "section": "Connectivity",
        "shortdescription": "An interrogation of 'togetherness'",
        "level": "Intermediate-advanced",
        "tagsstem": "multi-user, text, internet, server, sockets",
        "tagsarts": "social, interactivity, translation, dasein ",
        "learningobjectives": "•  Learn to set up a basic webserver.\n•  Gain experience working with a backend web framework.\n•  Design, develop and execute a concept for a social space.",
        "brief": "Develop a multi-user environment that allows people in different spaces to communicate with each other in a new way. Your environment could facilitate language-based interactions like typing, speaking or reading. Or it could convey other aspects of presence, such as gesture, breath or body dynamics, to explore what Heidegger calls *dasein*, or “being there together”. Carefully consider the agency of users in your system. Are they passive observers, listening to the murmurings of a crowd, or are they direct contributors to a grand conversation?  Give consideration to the way in which your work attends to the timing of interactions. Is communication asynchronous where messages or traces of users are encountered by others later? Or is it synchronous allowing for participation in a live event. What makes your environment experimental?",
        "variations": "•  Develop multi-user performance space for theater or performance. How can developing a medium through which participants are connected, augment or modify collaborative practices such as these?\n\n",
        "advancedstudents": "•  Create a multiuser environment where one user is an artificial intelligence. You may choose to use natural language processing tools such as Eliza or Rita or create one of your own. • Develop a Multi-User Dungeon (MUD) game which incorporates a chat room. A MUD is an interactive text based game where users collaborate to solve problems and progress the narrative. The first MUD was developed in 1978 and served as one of the earliest online chat rooms, making this variation a rich opportunity to study gaming history. Traditionally these were role playing games and users would choose to join a specific group based on common interests.",
        "makingitmeaningful": "One of the most evocative experiences offered by digital networks is being connected to someone when physically apart. The creatation of social spaces has characterised networked computation since its inception with some of the earliest chat programs being written in the 1960s and 1970s. The decades that followed the development of the internet brought bulliten board systems, MUDs, text based protocols such as IRC, the public chat rooms of the 1990s and, more recently, instant messanger services and multiuser documents. The magic of first using a multiuser shared document, where changes update in real time is hard to overemphasize to younger students accustomed to such tools.\n\nOf course communication is not confined to language and explorations of multi-modal communication spaces has long concerned media artists. Telepresence works pioneered ways to connect separated audiences prior to the ubiquity of the internet. Kit Galloway and Sherrie Rabinowitz’s Hole in Space (1980) is an early example using video. Multi-user drawing tools like MotionPhone (1990) by Scott Snibbe also shows early experiments developing collaborative creative tools. This assignment could be further focused on gesture or on autonomic body functions.",
        "titlegray": 255,
        "fullpageimage": "chat/hole_in_space_large.jpg",
        "layout": 20,
        "image": "chat/the_trace.jpg\nchat/listening_post.jpg\nchat/motion_phone.jpg\nchat/pckwck.jpg\nchat/poop_chat_pro.jpg",
        "aspirationcaptions": "1. Hole in Space (1980) by Kit Galloway and Sherrie Rabinowitz is an pioneering example of telepresence works as it connected audiences between Times Square in New York City and Los Angeles. https://www.youtube.com/watch?v=SyIJJr6Ldg8\n2. In The Trace (19XX) by Raphael Lorenzo Hemmer, one participant encounters the presnence of another person located in an identical but separate room. Each is conveyed to the other in light. http://www.lozano-hemmer.com/the_trace.php\n3. Listening Post (200X) Mark Hansen and Ben Rubin publicly displays phrases from conversations taken from public online chatrooms.\n4. Motion Phone (1995) Scott Snibbe is an early example of a collaborative drawing environment. Users are able to zoom in and draw at multiple scales. http://www.snibbe.com/projects/interactive/motionphone/\n5. PckWck, (2015) Sam Lavigne and Useless Press is an online space showing an author writing a novel in real time. Users are able to communicate with the novelist and each other via a chatroom.\n6. Poop Chat Pro, (20XX) Maddy Varner is an asynchonous chat space where messages are deposited as quivering animations for others to find later.",
        "additionalreferences": "Wafaa Bilal, (2007) Domestic Tension, http://wafaabilal.com/domestic-tension/\nExonemo, (2015) The Internet Bedroom - http://idpw.org/bedroom/\nJenny Holtzer, (1997) Trusim - http://www.medienkunstnetz.de/works/truisms/ \nJilian Mayer, (2012) The Sleep Site - http://aplaceforonlinedreaming.com/\nChat.meatspac.es, Soledad Penadés - https://chat.meatspac.es/\nCan we talk (2011) Zach Gage. https://vimeo.com/27421540\nJingwen Zhu, Real Me. http://www.jingwen-zhu.com/real-me/ \nKen Goldberg and Joseph Santarromana, (1995) Telegarden. http://www.ieor.berkeley.edu/~goldberg/garden/Ars/\nMarie Sester, (2003) Access. http://www.accessproject.net/concept.html\nKyle McDonald, (2015) Exhausting a Crowd. http://www.exhaustingacrowd.com/london \nTwistori, http://twistori.com/ \nMoniker - https://studiomoniker.com/projects/out-of-line",
        "notes": "Considerations: \nRole of the user: viewer or contributor: Are you just listening to the murmurings of a crowd, or able to contribute to it\nAsynchronous vs. Synchronous: participating in a live event, or contributing to a graffiti wall\nTextual or multimodal: Am I typing/speaking/reading, or am i using gesture, breath, my body\n\n\n"
    },
    {
        "in": 1,
        "titles": "Browser Extension",
        "section": "Connectivity",
        "shortdescription": "Lens for the internet",
        "level": "Intermediate",
        "tagsstem": "internet, browser, extension, add-on, network ",
        "tagsarts": "détournement, intervention, interactivity, defamiliarization, modding",
        "learningobjectives": "•  Develop an understanding of protocols for website structure and display\n•  Develop an understanding of Internet browser functionality\n•  Creation of a browser based creative intervention",
        "brief": "A *browser extension* is a software add-on that alters the behavior of a web browser application. Extensions can do things like change how specific online content appears, add additional content layers, redirect a viewer to different URLs, or change browser behaviors. It is a fruitful site for creative intervention in the online realm. Build a browser extension that programmatically alters the appearance of the Internet, or which augments or estranges a viewer's browsing experience in a poetic or critical way. Publish your extension to a public platform like the Chrome store. \n",
        "variations": "Inexperienced students can be introduced to online interventions through a preliminary exercise of modifying website code in the console of the browser. The styling and content of a page can be temporarily edited by changing the CSS or HTML of a page directly or algorithmically using JavaScript. This introductory exercise introduces students to the console, to the basic structure and compilation of a website. This experimentation can scaffold the creation of their extension. \n\nThis brief may be further constrained by narrowing it to one specific intervention, such as a text modification, a word or image find-and-replace, a style-based CSS change, or a content augmentation in which an extra layer of information is added to websites. ",
        "advancedstudents": "•  Make an extension that augments the web through use of data from an external online API or database. \n•  Build an addon that incorporates a multiuser functionality so that it connects or makes the audience aware of others using the same extension. This requires the use of web sockets or a similar.\n• Incorporate a regular expression.",
        "makingitmeaningful": "Like a window mediates a view of the physical world, the browser mediates the internet. It is a small but critical piece of infrastructure in the complex system that underlies all of our online activities. Building a creative extension is an opportunity for online intervention at a systems and/or content level. Software studies texts such as the now canonical *Protocol* by Alex Galloway approach the internet from the perspective of infrastructure and protocol, and theoretically scaffold creative interventions through which the browser’s operation and the contruction of the web is revealed.\n \nCreative online interventions that manipulate everyday content build on ideas from conceptual art history. The Situationalists used strategies like detournment and derive to estrange the mundane and everyday experience of life and these are historic precedents to art extensions that modify navigation across the web such as *We See in Every Direction* by Jonas Lund, or that find and replace content like *Rose Colored Window* by Katie Rose Pipkin. Extensions can also be tools for critical art and activism, through strategic edits or by explicating and revealing otherwise obscure relationships by layering additional information. See the Sunlight Foundation’s *Influence Explorer* or the *BookIndy Browse Amazon, Buy Local*.",
        "titlegray": 0,
        "fullpageimage": "extension/decoder.jpg",
        "layout": 24,
        "image": "extension/wesee.jpg\nextension/addart-1.jpg\nextension/newstweek.jpg\nextension/us.jpg\n",
        "aspirationcaptions": "1. Melanie Hoff's *Decodelia* (2015) uses principles of color theory to render the browser’s content visible only to those wearing red-tinted glasses. https://melanie-hoff.com/DECODELIA/\n2. Jonas Lund's *We See in Every Direction* (2013) connects all concurrent users in a collaborative browsing experience. http://ineverydirection.net/\n3. Although this isn't an extension *per se*, Newstweek enables users to change news websites by logging into a custom WiFi network. The connected router then injects the modified content to be seen by other users on the network. By Julian Oliver and Daniil Vasiliev (2011),  https://julianoliver.com/output/newstweek\n4. Steve Lambert's *Add Art* (2008) automatically replaces online advertisements with art. http://add-art.org/\n5. Us+ (2013) by Lauren McCarthy and Kyle Mcdonald is an addon for Google facetime, it analyzes conversation dynamics and attempts to offer suggestions for improving the interaction. http://lauren-mccarthy.com/us",
        "additionalreferences": "Burtch, Allison. *Internet Illuminator* (2014). http://www.allisonburtch.net/illuminator/\nDebord, Guy. \"A User’s Guide to Détournement (1).\" (1956).\nGalloway, Alexander. *Protocol: How Control Exists after Decentralization* (2001).\nLavigne, Sam and Tega Brain. *The Intergovernmental Panel on Capitalism* (2015). http://intergovernmentalpaneloncapitalism.org/\nMcNeil, Joanne. *Emotional Labor* (2015). http://www.joannemcneil.com/ga®llery/emotional-labor/\nDavid Nicholls, BookIndy, Browse Amazon, Buy Independent addon. http://bookindy.com/\nPhiffer, Dan and Mushon Zer-Aviv. *ShiftSpace* (2007). https://en.wikipedia.org/wiki/ShiftSpace\nPipkin, Katie Rose. *Rose Colored Window* (2015).\nThe New York Times Special Edition. http://nytimes-se.com/\nSimon, Joel. *FB Graffiti* (2014). http://www.joelsimon.net/fb-graffiti.html\nSunlight Foundation, *Influence Explorer* (2013).\nDarius Kazemi, Ethical Ad Blocker (2015). http://tinysubversions.com/notes/ethical-ad-blocker/\n\n"
    },
    {
        "in": 1,
        "titles": "Software Instrument",
        "section": "Interactivity",
        "shortdescription": "Virtual synaesthesia",
        "level": "Introduction",
        "tagsstem": "gesture, events, libraries, interaction design.",
        "tagsarts": "timbre, translation, rhythm, composition, harmony",
        "learningobjectives": "•  Apply the principles of interaction design to create a software instrument.\n•  Creatively explore ways to connect sound and visuals.\n•  Develop an understanding of event driven programming.",
        "brief": "Create an audiovisual instrument: a tool or toy that responds to a user's actions with tightly coupled sounds and imagery. Interactions with your instrument should yield predictable results. \n\nCarefully consider the interaction design of your instrument: Consider compositional elements such as musical scales, timbre and the variability of these things. Use your instrument to create a brief composition or performance.",
        "variations": "Inexperienced students may find it easier to deal with discrete inputs (like button presses, rather than continuous gestures), and discrete outputs (as in triggering pre-recorded sounds, rather than synthesizing sounds through the modulation of continuous parameters). Consider developing a \"QWERTY instrument\" which is performed through typing actions on a standard computer keyboard. Embed your instrument in a web page and publish it online. If you are using pre-recorded sounds, consider where they are sourced from, how they are visualized, and how this supports a coherent concept. ",
        "advancedstudents": "•  Explore the instrumental possibilities of continuous gesture input using physical sensors, computer vision (such as a face-tracker), or commodity motion capture hardware (such as a Wii Remote, Kinect depth sensor, or Leap Motion hand tracker).\n•  Explore the use of arts-oriented machine learning libraries, such as Rebecca Fiebrink's *Wekinator* or Nick Gillian's *Gesture Recognition Toolkit*, to enhance the intuitiveness of the mappings you establish between inputs and outputs. \n•  Divide your instrument into sub-systems (for input, graphics, and sound synthesis) which communicate over OSC. Consider using different development environments for each component (e.g. Max/MSP for sound, etc.).",
        "makingitmeaningful": "Synesthesia couples one sense with another and those with the condition report of hearing images, tasting sounds or seeing images. Similarly, designing tools for translating between the senses has been an ongoing source of inspiration for creators as can be seen in the rich history of color organs that spans centuries. Since the 1700s examples of color organs pair sounds and colors using key triggered popup panels, curtains that opened to show colored plates or later, with the invention of electricity, colored lights and projections. Along with these elaborate inventions, various artists, scientists and thinkers have attempted to design color scales, systems that structure correspondences between the elements of color (hue, saturation and value) and those of sound (pitch, amplitude, and tone color) see examples by Isaac Newton, D. D. Jameson and A. W. Rimmington. More recenlty, 20th century painters such as Kandinsky have also been captivated by the translation between the visual and the sonic domains, describing his paintings as compositions or symphonies, comprised of visual “chords”.\nThe availability of opensource software and hardware environments during the last decades have led to further experimentation with these ideas and take the form of new musical interfaces such as Imogen Heap's gloves, experimental sound tools like SUFI Plugins and new instruments like Amit Pitaru's Sonic Wire Sculpture. More examples of can be found in the analog synthesizer community, published as smartphone applications or websites, as addons to existing music production suites or as stand alone applications.",
        "titlegray": 255,
        "fullpageimage": "instrument/levin-lieberman.jpg",
        "layout": 20,
        "image": "instrument/pitaru_282x210.jpg\ninstrument/heap_282x210.jpg\ninstrument/rokeby_282x136.jpg\ninstrument/sufi_282x136.jpg\ninstrument/patatap_282x136.jpg",
        "aspirationcaptions": "1. The Manual Input Work Station, 2004 by Golan Levin and Zach Lieberman. http://flong.com/projects/miw/\n2. Sonic Wire Sculpture by Amit Pitaru. http://sws.cc/index.html\n3. Imogen Heap‘s software gloves. http://imogenheap.com/home.php?  \n4. David Rokeby’s Very Nervous System (1982-1991). http://www.davidrokeby.com/vns.html \n5. SUFI PLUG INS by Jace Clayton. http://www.beyond-digital.org/sufiplugins/\n6. Patatap by Jono Brandel and Lullatone. http://patatap.com/\n\n\n",
        "additionalreferences": "Rebecca Fiebrink’s Wekinator software tools. http://www.wekinator.org/downloads/\nAlison Parish makes instruments for writing that take on the principles of musical instruments.  http://www.decontextualize.com/projects/nite/\nCory Arcangel, Keyboard Instruments. http://www.coryarcangel.com/things-i-made/2009-003-dreiklavierstucke-op-11"
    }
]